@article{Craswell2020ORCAS2M,
  title={ORCAS: 20 Million Clicked Query-Document Pairs for Analyzing Search},
  author={Nick Craswell and Daniel Fernando Campos and Bhaskar Mitra and E. Yilmaz and Bodo Billerbeck},
  journal={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  year={2020}
}
@inproceedings{Karpukhin2020DensePR,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  author={V. Karpukhin and Barlas OÄŸuz and Sewon Min and Patrick Lewis and Ledell Yu Wu and Sergey Edunov and Danqi Chen and Wen-tau Yih},
  booktitle={EMNLP},
  year={2020}
}
@article{Shen2016ReasoNetLT,
  title={ReasoNet: Learning to Stop Reading in Machine Comprehension},
  author={Y. Shen and Po-Sen Huang and Jianfeng Gao and W. Chen},
  journal={Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year={2016}
}
@article{Wang2017MachineCU,
  title={Machine Comprehension Using Match-LSTM and Answer Pointer},
  author={Shuohang Wang and Jing Jiang},
  journal={ArXiv},
  year={2017},
  volume={abs/1608.07905}
}
@article{Campos2016MSMA,
  title={MS MARCO: A Human Generated MAchine Reading COmprehension Dataset},
  author={Daniel Fernando Campos and T. Nguyen and M. Rosenberg and Xia Song and Jianfeng Gao and Saurabh Tiwary and Rangan Majumder and L. Deng and Bhaskar Mitra},
  journal={ArXiv},
  year={2016},
  volume={abs/1611.09268}
}
@article{Chuklin2013ClickMI,
  title={Click model-based information retrieval metrics},
  author={A. Chuklin and P. Serdyukov and M. Rijke},
  journal={Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval},
  year={2013}
}
@inproceedings{Devlin2019BERTPO,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={J. Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle={NAACL-HLT},
  year={2019}
}
@article{Mitra2020NeuralMF,
  title={Neural Methods for Effective, Efficient, and Exposure-Aware Information Retrieval},
  author={Bhaskar Mitra},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.11685}
}
@article{Ansari2020IdentifyingSD,
  title={Identifying Semantically Duplicate Questions Using Data Science Approach: A Quora Case Study},
  author={Navedanjum Ansari and R. Sharma},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.11694}
}
@article{Bhatia2020ExGANAG,
  title={ExGAN: Adversarial Generation of Extreme Samples},
  author={Siddharth Bhatia and Arjit Jain and Bryan Hooi},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.08454}
}
@article{Li2020TrainLT,
  title={Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers},
  author={Zhuohan Li and Eric Wallace and Sheng Shen and Kevin Lin and K. Keutzer and D. Klein and J. Gonzalez},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.11794}
}
@inproceedings{LeCun1989OptimalBD,
  title={Optimal Brain Damage},
  author={Y. LeCun and J. Denker and S. Solla},
  booktitle={NIPS},
  year={1989}
}
@article{Ba2014DoDN,
  title={Do Deep Nets Really Need to be Deep?},
  author={Jimmy Ba and R. Caruana},
  journal={ArXiv},
  year={2014},
  volume={abs/1312.6184}
}
@article{Frankle2019TheLT,
  title={The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks},
  author={Jonathan Frankle and Michael Carbin},
  journal={arXiv: Learning},
  year={2019}
}
@inproceedings{Voita2019AnalyzingMS,
  title={Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned},
  author={Elena Voita and David Talbot and F. Moiseev and Rico Sennrich and Ivan Titov},
  booktitle={ACL},
  year={2019}
}
@article{Wang2019StructuredPF,
  title={Structured Pruning for Efficient ConvNets via Incremental Regularization},
  author={H. Wang and Qiming Zhang and Yuehai Wang and H. Hu},
  journal={2019 International Joint Conference on Neural Networks (IJCNN)},
  year={2019},
  pages={1-8}
}
@article{Kwon2019StructuredCB,
  title={Structured Compression by Unstructured Pruning for Sparse Quantized Neural Networks},
  author={S. Kwon and D. Lee and Byeongwook Kim and Parichay Kapoor and Baeseong Park and Gu-Yeon Wei},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.10138}
}
@article{Han2016DeepCC,
  title={Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding},
  author={Song Han and Huizi Mao and W. Dally},
  journal={arXiv: Computer Vision and Pattern Recognition},
  year={2016}
}
@article{Brown2020LanguageMA,
  title={Language Models are Few-Shot Learners},
  author={T. Brown and B. Mann and Nick Ryder and Melanie Subbiah and J. Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and G. Kr{\"u}ger and T. Henighan and R. Child and Aditya Ramesh and D. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and E. Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and J. Clark and Christopher Berner and Sam McCandlish and A. Radford and Ilya Sutskever and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.14165}
}
@article{Howard2017MobileNetsEC,
  title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  author={A. Howard and Menglong Zhu and Bo Chen and D. Kalenichenko and W. Wang and Tobias Weyand and M. Andreetto and H. Adam},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.04861}
}
@article{Seo2017BidirectionalAF,
  title={Bidirectional Attention Flow for Machine Comprehension},
  author={Minjoon Seo and Aniruddha Kembhavi and Ali Farhadi and Hannaneh Hajishirzi},
  journal={ArXiv},
  year={2017},
  volume={abs/1611.01603}
}
@article{Zhao2017RecurrentCN,
  title={Recurrent convolutional neural network for speech processing},
  author={Y. Zhao and Xingyu Jin and Xiaolin Hu},
  journal={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year={2017},
  pages={5300-5304}
}
@article{Kaplan2020ScalingLF,
  title={Scaling Laws for Neural Language Models},
  author={J. Kaplan and Sam McCandlish and T. Henighan and T. Brown and Benjamin Chess and R. Child and Scott Gray and A. Radford and Jeffrey Wu and Dario Amodei},
  journal={ArXiv},
  year={2020},
  volume={abs/2001.08361}
}
@inproceedings{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Nets},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and M. Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  booktitle={NIPS},
  year={2014}
}
@article{Madaan2019AdversarialNP,
  title={Adversarial Neural Pruning with Latent Vulnerability Suppression},
  author={Divyam Madaan and Jinwoo Shin and Sung Ju Hwang},
  journal={arXiv: Learning},
  year={2019}
}
@inproceedings{Molchanov2017VariationalDS,
  title={Variational Dropout Sparsifies Deep Neural Networks},
  author={D. Molchanov and Arsenii Ashukha and D. Vetrov},
  booktitle={ICML},
  year={2017}
}
@inproceedings{Wang2018KDGANKD,
  title={KDGAN: Knowledge Distillation with Generative Adversarial Networks},
  author={X. Wang and Rui Zhang and Y. Sun and Jianzhong Qi},
  booktitle={NeurIPS},
  year={2018}
}
@inproceedings{Wang2018DistillingKW,
  title={Distilling Knowledge with Adversarial Networks},
  author={Xiaojie Wang and R. Zhang and Yu Sun and Jianzhong Qi},
  booktitle={NIPS 2018},
  year={2018}
}
@article{Dhillon2018StochasticAP,
  title={Stochastic Activation Pruning for Robust Adversarial Defense},
  author={Guneet S. Dhillon and Kamyar Azizzadenesheli and Zachary Chase Lipton and J. Bernstein and Jean Kossaifi and A. Khanna and Anima Anandkumar},
  journal={ArXiv},
  year={2018},
  volume={abs/1803.01442}
}
@inproceedings{Guo2018SparseDW,
  title={Sparse DNNs with Improved Adversarial Robustness},
  author={Yiwen Guo and Chao Zhang and C. Zhang and Y. Chen},
  booktitle={NeurIPS},
  year={2018}
}
@article{Sehwag2020OnPA,
  title={On Pruning Adversarially Robust Neural Networks},
  author={V. Sehwag and Shiqi Wang and P. Mittal and Suman Jana},
  journal={ArXiv},
  year={2020},
  volume={abs/2002.10509}
}
@inproceedings{Dass2006SecretsBT,
  title={Secrets behind the Nim game},
  author={Jennifer Kirubai Victor Christ Dass},
  year={2006}
}
@article{Polino2018ModelCV,
  title={Model compression via distillation and quantization},
  author={A. Polino and Razvan Pascanu and Dan Alistarh},
  journal={ArXiv},
  year={2018},
  volume={abs/1802.05668}
}
@article{Sanh2020MovementPA,
  title={Movement Pruning: Adaptive Sparsity by Fine-Tuning},
  author={Victor Sanh and Thomas Wolf and Alexander M. Rush},
  journal={ArXiv},
  year={2020},
  volume={abs/2005.07683}
}
@article{Courbariaux2016BinarizedNN,
  title={Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1},
  author={Matthieu Courbariaux and Itay Hubara and Daniel Soudry and Ran El-Yaniv and Yoshua Bengio},
  journal={arXiv: Learning},
  year={2016}
}
@article{Gong2014CompressingDC,
  title={Compressing Deep Convolutional Networks using Vector Quantization},
  author={Yunchao Gong and L. Liu and Ming Yang and Lubomir D. Bourdev},
  journal={ArXiv},
  year={2014},
  volume={abs/1412.6115}
}
@inproceedings{Vaswani2017AttentionIA,
  title={Attention is All you Need},
  author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and L. Kaiser and Illia Polosukhin},
  booktitle={NIPS},
  year={2017}
}
@inproceedings{Sehwag2020HYDRAPA,
  title={HYDRA: Pruning Adversarially Robust Neural Networks},
  author={V. Sehwag and Shiqi Wang and P. Mittal and Suman Jana},
  booktitle={NeurIPS},
  year={2020}
}
@article{Michel2019AreSH,
  title={Are Sixteen Heads Really Better than One?},
  author={Paul Michel and Omer Levy and Graham Neubig},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.10650}
}
@article{Sanh2019DistilBERTAD,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}
@article{BoutonNimAG,
  title={Nim, A Game with a Complete Mathematical Theory},
  author={C. L. Bouton},
  journal={Annals of Mathematics},
  volume={3},
  pages={35}
}
@article{Hubara2017QuantizedNN,
  title={Quantized Neural Networks: Training Neural Networks with Low Precision Weights and Activations},
  author={Itay Hubara and Matthieu Courbariaux and Daniel Soudry and Ran El-Yaniv and Yoshua Bengio},
  journal={J. Mach. Learn. Res.},
  year={2017},
  volume={18},
  pages={187:1-187:30}
}

@article{Hinton2015DistillingTK,
  title={Distilling the Knowledge in a Neural Network},
  author={Geoffrey E. Hinton and Oriol Vinyals and J. Dean},
  journal={ArXiv},
  year={2015},
  volume={abs/1503.02531}
}
@article{CIFAR-10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html},
abstract= {The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. },
keywords= {Dataset},
terms= {}
}
@inproceedings{Krizhevsky2009LearningML,
  title={Learning Multiple Layers of Features from Tiny Images},
  author={A. Krizhevsky},
  year={2009}
}
@article{Jia2020StochasticMP,
  title={Stochastic Model Pruning via Weight Dropping Away and Back},
  author={Haipeng Jia and Xueshuang Xiang and D. Fan and Meiyu Huang and Changhao Sun and Yang He},
  journal={2020 2nd International Conference on Image Processing and Machine Vision},
  year={2020}
}
@article{Bartoldson2019TheGT,
  title={The Generalization-Stability Tradeoff in Neural Network Pruning},
  author={Brian Bartoldson and Ari S. Morcos and Adrian Barbu and G. Erlebacher},
  journal={ArXiv},
  year={2019},
  volume={abs/1906.03728}
}
@inproceedings{Chen2017DualPN,
  title={Dual Path Networks},
  author={Y. Chen and J. Li and H. Xiao and X. Jin and S. Yan and Jiashi Feng},
  booktitle={NIPS},
  year={2017}
}
@article{Russakovsky2015ImageNetLS,
  title={ImageNet Large Scale Visual Recognition Challenge},
  author={Olga Russakovsky and J. Deng and H. Su and J. Krause and S. Satheesh and S. Ma and Zhiheng Huang and A. Karpathy and A. Khosla and M. Bernstein and A. Berg and Li Fei-Fei},
  journal={International Journal of Computer Vision},
  year={2015},
  volume={115},
  pages={211-252}
}
@article{Simonyan2015VeryDC,
  title={Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author={K. Simonyan and Andrew Zisserman},
  journal={CoRR},
  year={2015},
  volume={abs/1409.1556}
}
@article{He2016DeepRL,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and X. Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}
@article{lecun-mnisthandwrittendigit-2010,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}
@article{Xie2020BlindAP,
  title={Blind Adversarial Pruning: Balance Accuracy, Efficiency and Robustness},
  author={Haidong Xie and Lixin Qian and Xueshuang Xiang and N. Liu},
  journal={ArXiv},
  year={2020},
  volume={abs/2004.05913}
}

@article{Blalock2020WhatIT,
  title={What is the State of Neural Network Pruning?},
  author={Davis W. Blalock and J. G. Ortiz and Jonathan Frankle and John Guttag},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.03033}
}
@article{Mitra2020ConformerKernelWQ,
  title={Conformer-Kernel with Query Term Independence for Document Retrieval},
  author={Bhaskar Mitra and Sebastian Hofst{\"a}tter and Hamed Zamani and Nick Craswell},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.10434}
}
@article{nogueira2019multi,
  title={Multi-stage document ranking with BERT},
  author={Nogueira, Rodrigo and Yang, Wei and Cho, Kyunghyun and Lin, Jimmy},
  journal={arXiv preprint arXiv:1910.14424},
  year={2019}
}
@inproceedings{hofstaetter_sigir_2019,
    author = {Hofst{\"a}tter, Sebastian and Rekabsaz, Navid and Eickhoff, Carsten and Hanbury, Allan},
    title = {On the Effect of Low-Frequency Terms on Neural-IR Models},
    booktitle = {Proceedings of SIGIR},
    year = {2019},
    publisher = {ACM}
}
@article{Hofsttter2019OnTE,
  title={On the Effect of Low-Frequency Terms on Neural-IR Models},
  author={Sebastian Hofst{\"a}tter and Navid Rekabsaz and Carsten Eickhoff and A. Hanbury},
  journal={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2019}
}

@article{Huang2013LearningDS,
  title={Learning deep structured semantic models for web search using clickthrough data},
  author={Po-Sen Huang and X. He and Jianfeng Gao and L. Deng and A. Acero and Larry Heck},
  journal={Proceedings of the 22nd ACM international conference on Information \& Knowledge Management},
  year={2013}
}
@article{Shen2014LearningSR,
  title={Learning semantic representations using convolutional neural networks for web search},
  author={Y. Shen and X. He and Jianfeng Gao and Li Deng and G. Mesnil},
  journal={Proceedings of the 23rd International Conference on World Wide Web},
  year={2014}
}
@article{Mitra2017LearningTM,
  title={Learning to Match using Local and Distributed Representations of Text for Web Search},
  author={Bhaskar Mitra and F. Diaz and Nick Craswell},
  journal={Proceedings of the 26th International Conference on World Wide Web},
  year={2017}
}
@inproceedings{10.1145/3159652.3159659,
author = {Dai, Zhuyun and Xiong, Chenyan and Callan, Jamie and Liu, Zhiyuan},
title = {Convolutional Neural Networks for Soft-Matching N-Grams in Ad-Hoc Search},
year = {2018},
isbn = {9781450355810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3159652.3159659},
doi = {10.1145/3159652.3159659},
abstract = {This paper presents textttConv-KNRM, a Convolutional Kernel-based Neural Ranking Model that models n-gram soft matches for ad-hoc search. Instead of exact matching query and document n-grams, textttConv-KNRM uses Convolutional Neural Networks to represent n-grams of various lengths and soft matches them in a unified embedding space. The n-gram soft matches are then utilized by the kernel pooling and learning-to-rank layers to generate the final ranking score. textttConv-KNRM can be learned end-to-end and fully optimized from user feedback. The learned modelÂ»s generalizability is investigated by testing how well it performs in a related domain with small amounts of training data. Experiments on English search logs, Chinese search logs, and TREC Web track tasks demonstrated consistent advantages of textttConv-KNRM over prior neural IR methods and feature-based methods.},
booktitle = {Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
pages = {126â€“134},
numpages = {9},
keywords = {relevance ranking, neural ir, n-gram soft match},
location = {Marina Del Rey, CA, USA},
series = {WSDM '18}
}


@article{Liu2019RethinkingTV,
  title={Rethinking the Value of Network Pruning},
  author={Zhuang Liu and M. Sun and Tinghui Zhou and Gao Huang and Trevor Darrell},
  journal={ArXiv},
  year={2019},
  volume={abs/1810.05270}
}
@inproceedings{Haidar2019TextKDGANTG,
  title={TextKD-GAN: Text Generation Using Knowledge Distillation and Generative Adversarial Networks},
  author={Md. Akmal Haidar and M. Rezagholizadeh},
  booktitle={Canadian Conference on AI},
  year={2019}
}
@inproceedings{Wang2018DistillingKW,
  title={Distilling Knowledge with Adversarial Networks},
  author={Xiaojie Wang and R. Zhang and Yu Sun and Jianzhong Qi},
  booktitle={NIPS 2018},
  year={2018}
}
@inproceedings{Zhang2020PKDGANPK,
  title={P-KDGAN: Progressive Knowledge Distillation with GANs for One-class Novelty Detection},
  author={Zhiwei Zhang and S. Chen and Lei Sun},
  booktitle={IJCAI},
  year={2020}
}